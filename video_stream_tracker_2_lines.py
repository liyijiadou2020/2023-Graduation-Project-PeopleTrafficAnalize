# import os
from collections import deque
import time
import cv2
import numpy as np
import os
import re
from person_count_utils import tlbr_midpoint, intersect, vector_angle, get_size_with_pil, compute_color_for_labels, \
    put_text_to_cv2_img_with_pil, draw_line, makedir, draw_statistics_to_frame, \
    draw_idx_frame, draw_newest_info_binary_lines
from utils.draw import draw_boxes_and_text, draw_reid_person, draw_boxes
from utils.torch_utils import select_device, load_classifier, time_synchronized
from sklearn.metrics.pairwise import cosine_similarity
from pathlib import Path

# test -
def increment_person_name(person_name):
    # Increment person name, i.e. person1.jpg --> person1-1.jpg, person1-2.jpg etc.
    path = os.path.abspath(person_name)  # os-agnostic
    if (os.path.exists(path)):
        dirs = [d for d in os.listdir(os.path.dirname(path)) if
                re.match(rf"{os.path.splitext(os.path.basename(path))[0]}-\d+\.\w+", d)]
        i = [int(re.search(r"\d+", d).group()) for d in dirs]  # indices
        n = max(i) + 1 if i else 1  # increment number
        new_name = f"{os.path.splitext(os.path.basename(path))[0]}-{n}{os.path.splitext(os.path.basename(path))[1]}"
        return f"{os.path.dirname(path)}{os.path.sep}{new_name}"  # update path
    else:
        return str(path)

class VideoStreamTracker_2_Lines():
    def __init__(self, yolo_model,
                 reid_model,
                 deepsort_model,
                 dataset,
                 feats,
                 names,
                 camera_name,
                 output_people_img_path,
                 p1, p2, p3, p4,
                 tracker_type_number=-1, is_display=True, is_save_vid=True):
        '''
        todo: é»˜è®¤å‚æ•°ï¼šcus_features - None, cus_names - [],  is_display - True, is_save_vid - False
        parameters:
            cus_features : reidä½¿ç”¨çš„æŸ¥è¯¢åº“çš„ç‰¹å¾
            output_people_img_path : å°†æå–å‡ºçš„äººç‰©å›¾åƒæ”¾åœ¨ä»€ä¹ˆè·¯å¾„ä¸‹
            is_display : æ˜¯å¦å±•ç¤ºè§†é¢‘
            p1, p2 : é»„çº¿çš„ä¸¤ä¸ªç«¯ç‚¹å ç”»é¢çš„æ¯”ä¾‹ï¼ˆ0-1ä¹‹é—´ï¼‰ï¼Œç”¨åˆ—è¡¨çš„å½¢å¼ä¼ é€’
            tracker_type_number : 0ä»£è¡¨å…¥å£æ‘„åƒå¤´ï¼Œ 1ä»£è¡¨å‡ºå£æ‘„åƒå¤´ï¼Œ å…¶ä»–æ•°å­—ä»£è¡¨åº—å†…æ‘„åƒå¤´
        '''
        self.idx_frame = 0
        self.total_track = 0
        self.total_counter = 0
        self.up_count = 0
        self.down_count = 0
        self.already_counted = deque(maxlen=100)
        self.yolo_model = yolo_model
        self.deepsort = deepsort_model
        self.dataset = dataset
        self.tracker_type_number = tracker_type_number
        # 1.ç”»é»„çº¿
        self.p1_ratio = p1
        self.p2_ratio = p2
        self.p3_ratio = p3
        self.p4_ratio = p4
        # 2.å¤„ç†tracks
        self._save_dir = output_people_img_path
        # 3.ReID
        self.reid_model = reid_model
        self.feats = feats
        self.names = names

        self.new_add_feats = np.ones((1, 512), dtype=np.int) # todo: æ–°å¢ï¼Œå¦‚æœå‘ç°è¯¥é•œå¤´ä¸‹æ–°å‡ºç°äº†äººï¼ŒæŠŠå®ƒæ”¾åˆ°å¢åŠ çš„featsä¸­
        self.new_add_names = []
        # ------- è®°å½•è§¦çº¿æ—¶é—´ -------
        self.camera_name = camera_name
        self.customers_log = {}
        # --------------------------
        # 4.ç»˜åˆ¶ç»Ÿè®¡ä¿¡æ¯ & ç»˜åˆ¶æ£€æµ‹æ¡† & ç»˜åˆ¶å¸§æ•°
        self.total_frame = 0
        # 5.å±•ç¤ºå›¾åƒï¼Œè¾“å‡ºç»“æœè§†é¢‘
        self.is_display = is_display
        self.is_save_vid = is_save_vid
        # 6.é”€æ¯çª—å£ & æ‰“å°log

    def track(self, query_feat=None, query_names=[], cus_log={}):
        # å¦‚æœä¸æ˜¯å…¥å£æ‘„åƒå¤´ï¼Œé‚£ä¹ˆåœ¨å¤„ç†ä¹‹å‰è¦æ›´æ–°ä¸€ä¸‹query_feat, cus_names
        if self.tracker_type_number != 0:
            self.update_reid_query(query_feat, query_names)
            self.customers_log = cus_log

        paths = {}  # æ¯ä¸€ä¸ªtrackçš„è¡ŒåŠ¨è½¨è¿¹
        last_track_id = -1
        # angle = -1
        is_in = False
        already_counted = deque(maxlen=100)  # temporary memory for storing counted IDs

        vid_path = None
        vid_writer = None

        '''
        imgï¼šå½“å‰å¸§çš„å›¾åƒæ•°æ®ï¼ˆnumpyæ•°ç»„ç±»å‹ï¼‰,è¡¨ç¤ºç»è¿‡ç¼©æ”¾æˆ–è£å‰ªåçš„å›¾åƒæ•°æ®ï¼Œè¿™æ˜¯ä¸ºäº†æ»¡è¶³YOLOç›®æ ‡æ£€æµ‹ç®—æ³•è¾“å…¥å›¾åƒçš„å¤§å°è¦æ±‚è€Œè¿›è¡Œçš„å¤„ç†ã€‚
        ori_imgï¼šå½“å‰å¸§çš„åŸå§‹å›¾åƒæ•°æ®ï¼ˆnumpyæ•°ç»„ç±»å‹ï¼‰,è¡¨ç¤ºæ²¡æœ‰è¿›è¡Œä»»ä½•å¤„ç†çš„åŸå§‹å›¾åƒæ•°æ®ï¼Œå®ƒç”¨äºåç»­çš„è·Ÿè¸ªå™¨æ›´æ–°å’Œç»“æœå¯è§†åŒ–ç­‰æ“ä½œã€‚
            åœ¨è¿™æ®µä»£ç ä¸­ï¼Œimgç”¨äºç›®æ ‡æ£€æµ‹ï¼Œori_imgç”¨äºè·Ÿè¸ªå’Œç»“æœæ˜¾ç¤ºã€‚
        vid_capï¼šè§†é¢‘çš„è¯»å–å™¨å¯¹è±¡ï¼ˆOpenCVä¸­çš„VideoCaptureç±»å‹ï¼‰
        '''
        for video_path, img, ori_img, vid_cap in self.dataset:  # è·å–è§†é¢‘å¸§
            self.idx_frame += 1
            start_time = time_synchronized()

            # yolo detection
            bbox_xywh, cls_conf, cls_ids, xy = self.yolo_model.detect(video_path, img, ori_img, vid_cap)
            if len(bbox_xywh) > 0: # åŠ ä¸Šè¿™å¥ï¼Œå¦‚æœæ²¡æ£€æµ‹åˆ°äººå°±ç›´æ¥è·³è¿‡è¿™ä¸€å¸§
                outputs, features = self.deepsort.update(bbox_xywh, cls_conf, ori_img)

            # 1.ç”»é»„çº¿
            yellow_line = draw_line(self.p1_ratio, self.p2_ratio, ori_img)
            green_line = draw_line(self.p3_ratio, self.p4_ratio, ori_img, (0, 255, 0))
            # 2. å¤„ç†tracks
            for track in outputs:
                bbox = track[:4]
                track_id = track[-1]
                midpoint_1 = tlbr_midpoint(bbox)
                origi_midpoint = (midpoint_1[0],
                                   ori_img.shape[0] - midpoint_1[1])  # get midpoint_1 respective to bottom-left
                if track_id not in paths:
                    paths[track_id] = deque(maxlen=2)  # pathä¿å­˜äº†æ¯ä¸ªtrackçš„ä¸¤ä¸ªå¸§çš„midpointï¼ˆè¿åŠ¨è½¨è¿¹ï¼‰
                    total_track = track_id
                paths[track_id].append(midpoint_1)
                midpoint_0 = paths[track_id][0]  # æ­¤trackå‰ä¸€å¸§çš„midpoint
                origin_previous_midpoint = (midpoint_0[0], ori_img.shape[0] - midpoint_0[1])

                if intersect(midpoint_1, midpoint_0, yellow_line[0], yellow_line[1]) \
                        and track_id not in already_counted: # è¿›å…¥
                    is_in = True
                    self.total_counter += 1
                    last_track_id = track_id;  # è®°å½•è§¦çº¿è€…çš„ID
                    cv2.line(ori_img, yellow_line[0], yellow_line[1], (0, 0, 255), 1)  # è§¦ç¢°çº¿çš„æƒ…å†µä¸‹ç”»çº¢çº¿
                    already_counted.append(track_id)  # Set already counted for ID to true.
                    self.up_count += 1
                    self.save_photo_and_wirte_log_add_new_feats(bbox, ori_img, track_id,
                                                                self.tracker_type_number)  # äººæµé‡ç»Ÿè®¡çš„ä¸»è¦å¤„ç†é€»è¾‘
                elif intersect(midpoint_1, midpoint_0, green_line[0], green_line[1]) \
                        and track_id not in already_counted: # ç¦»å¼€
                    is_in = False
                    self.total_counter += 1
                    last_track_id = track_id;  # è®°å½•è§¦çº¿è€…çš„ID
                    cv2.line(ori_img, green_line[0], green_line[1], (0, 0, 255), 1)  # è§¦ç¢°çº¿çš„æƒ…å†µä¸‹ç”»çº¢çº¿
                    already_counted.append(track_id)  # Set already counted for ID to true.
                    self.down_count += 1

            # 3.é‡è¯†åˆ«ç»“æœ - Enteræ‘„åƒå¤´ä¸éœ€è¦ç®¡è¿™ä¸ª
            if self.tracker_type_number != 0:
                img, match_names = self.draw_reid_result_to_frame(features, ori_img, xy) #todo: bug

            # 4.ç»˜åˆ¶ç»Ÿè®¡ä¿¡æ¯
            ori_img = self.draw_box_and_info_to_frame(is_in, last_track_id, ori_img, outputs, self.total_track)

            # 5.å±•ç¤ºå›¾åƒï¼Œè¾“å‡ºç»“æœè§†é¢‘
            if self.is_display:
                cv2.namedWindow("frame", 0) # å¯ä»¥è°ƒæ•´çª—å£å¤§å°
                # cv2.resizeWindow("frame", 1600, 900)  # è®¾ç½®é•¿å’Œå®½
                cv2.imshow("frame", ori_img)
                if cv2.waitKey(1) & 0xFF == 27:
                    break
            end_time = time_synchronized()
            print("Index of frame: {} "
                              "Spend time: {:.03f}s, "
                              "Fps: {:.03f}, "
                              "Tracks : {}, "
                              "Detections : {}, "
                              "Features of detections: {}"
                              .format(self.idx_frame
                                      # , self.total_frame_count
                                      , end_time - start_time
                                      , 1 / (end_time - start_time)
                                      , bbox_xywh.shape[0]
                                      , len(outputs)
                                      , len(bbox_xywh)
                                      , features.shape
                                      )
                              )
            if self.is_save_vid: # è¾“å‡ºè§†é¢‘
                if vid_path != self._save_dir:
                    vid_path = self._save_dir
                    if isinstance(vid_writer, cv2.VideoWriter):
                        vid_writer.release()
                    if vid_cap:  # video
                        fps = vid_cap.get(cv2.CAP_PROP_FPS)
                        w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                        h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                    else:  # stream
                        fps, w, h = 30, ori_img.shape[1], ori_img.shape[0]
                    save_path = str(
                        Path(self._save_dir).with_suffix('.mp4'))  # force *.mp4 suffix on results videos
                    vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))
                vid_writer.write(ori_img)
        cv2.destroyAllWindows()  ## é”€æ¯æ‰€æœ‰opencvæ˜¾ç¤ºçª—å£

        if self.tracker_type_number == 0: # å¦‚æœè¿™æ˜¯å…¥å£æ‘„åƒå¤´ï¼Œéœ€è¦æå–ç‰¹å¾åç»­ä½¿ç”¨
            feats, names = self.feature_extract()
            self.save_feats_names_to_dir(feats, names)
            customer_logs = self.customers_log
            return feats, names, customer_logs
        else:
            # todo: æŠŠè¿™ä¸ªé•œå¤´ä¸‹æ–°å‡ºç°çš„featå’Œnameä¹Ÿæ·»åŠ åˆ°query_featureså’Œnamesé‡Œå»------
            # new_add_featséœ€è¦ç¿»è½¬
            self.new_add_feats = self.new_add_feats[:-1, :] # å–æ‰€æœ‰è¡Œï¼Œä½†ä¸åŒ…æ‹¬æœ€åä¸€è¡Œ
            self.new_add_names = self.new_add_names[::-1] # åå­—ç¿»è½¬
            self.new_add_names.append("None")

            self.feats = np.concatenate((self.feats, self.new_add_feats), axis=0)
            self.names = self.names[:-1] + self.new_add_names # å»æ‰namesçš„æœ€åä¸€ä¸ª"None"

            # ---------------
            feats, names, customer_logs = self.feats, self.names, self.customers_log
            return feats, names, customer_logs
            # ------------------------------------------------
        # vid_writer.release()

    def save_photo_and_wirte_log_add_new_feats(self, bbox, ori_img, track_id, tracker_type_number):
        # ------- reid è·å– person_name --------
        ROI_person = ori_img[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]
        person_feature = self.reid_model(ROI_person)
        person_name = self.save_photo_and_get_person_name_by_reid(bbox, ori_img, track_id, tracker_type_number,
                                                                  self.camera_name)
        # ------------ è®°å½•log ----------
        current_time = int(time.time())
        localtime = time.localtime(current_time)
        dt = time.strftime('%Y-%m-%d %H:%M:%S', localtime)
        if self.tracker_type_number == 0:  # å…¥å£æ‘„åƒæœºï¼Œè®°å½•æ‰€æœ‰è¿›å…¥çš„äºº
            self.customers_log[person_name] = {self.camera_name: dt}
        else:
            if person_name not in self.customers_log:
                self.customers_log[person_name] = {self.camera_name: dt}
                # ------- todo: æ·»åŠ æ–°çš„å¤–è§‚å‘é‡ + name -----------------
                self.new_add_feats = np.concatenate((person_feature, self.new_add_feats), axis=0) #todo: æœ€åéœ€è¦ç¿»è½¬ä¸€ä¸‹
                self.new_add_names.append(person_name)
                # ---------------------------------------------
            else:
                self.customers_log[person_name][self.camera_name] = dt

        # ------- print info to console æ‰“å°å½“å‰çš„æ—¶é—´ & é¡¾å®¢å…¥åº—ä¿¡æ¯ -------
        welcome_str = "[Customer cameğŸ‘]" if self.tracker_type_number == 0 else "[ReID ResultğŸ™Œ]"
        print(" {} current customerğŸ’‚â€â™‚ï¸: {}, "
              " timeâ° : {}".format(
            welcome_str
            ,person_name
            ,dt
        ))


    def save_photo_and_get_person_name_by_reid(self, bbox, ori_img, track_id, tracker_tpye_number, cam_name):
        ROI_person = ori_img[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]
        # person_name = '{}-{}'.format(cam_name, track_id)
        person_name = '{}-{}'.format('cus', track_id)
        path = str(self._save_dir + '/' + person_name + '.jpg')

        if tracker_tpye_number != 0:
            person_feature = self.reid_model(ROI_person)
            # ---- compare -----------
            cos_sim = cosine_similarity(self.feats, person_feature)
            max_idx = np.argmax(cos_sim, axis=1)  # æ¯è¡Œæœ€å¤§å€¼çš„ç´¢å¼•
            maximum = np.max(cos_sim, axis=1)
            print("[ReID DEBUG] maximum = ", max(maximum))
            if max(maximum) > 0.5:
                max_idx[maximum < 0.5] = -1
                idx = np.argmax(max_idx)
                person_name = self.names[idx]  # æœå¯»å¾—åˆ°çš„
            else:
                # person_name = '{}-{}'.format(cam_name, track_id)
                person_name = '{}-{}-{}'.format(cam_name,'cus', track_id)
            path = str(self._save_dir + '/' + person_name + '.jpg')
            if os.path.exists(path):
                path = increment_person_name(path)

        makedir(path)
        cv2.imwrite(path, ROI_person)
        return person_name

    def draw_box_and_info_to_frame(self, is_in, last_track_id, ori_img, outputs, total_track):
        ori_img = draw_statistics_to_frame(self.down_count, ori_img, self.total_counter, total_track, self.up_count)
        ori_img = draw_idx_frame(ori_img, self.idx_frame)
        if last_track_id >= 0:
            ori_img = draw_newest_info_binary_lines(is_in, last_track_id, ori_img)  # æ‰“å°æ’çº¿äººçš„ä¿¡æ¯
        if len(outputs) > 0:  # å±•ç¤ºè·Ÿè¸ªç»“æœ
            bbox_tlwh = []
            bbox_xyxy = outputs[:, :4]
            identities = outputs[:, -1]
            draw_boxes_and_text(ori_img, bbox_xyxy, identities)  # ç»™æ¯ä¸ªdetectionç”»æ¡†
            for bb_xyxy in bbox_xyxy:
                bbox_tlwh.append(self.deepsort._xyxy_to_tlwh(bb_xyxy))
        return ori_img

    def draw_reid_result_to_frame(self, features, ori_img, xy):
        person_cossim = cosine_similarity(features, self.feats)  # è®¡ç®—featureså’Œquery_featuresçš„ä½™å¼¦ç›¸ä¼¼åº¦
        max_idx = np.argmax(person_cossim, axis=1)
        maximum = np.max(person_cossim, axis=1)
        max_idx[maximum < 0.5] = -1
        score = maximum
        reid_results = max_idx
        img, match_names = draw_reid_person(ori_img, xy, reid_results, self.names)  # todo:bug
        return img, match_names

    def update_reid_query(self, features, names):
        self.feats = features
        self.names = names

    def feature_extract(self): # TODO: å¹¶ä¸æ˜¯ååˆ†å¦¥å½“ï¼
        # reid_feature = Reid_feature() # reid model
        names = []
        embs = np.ones((1, 512), dtype=np.int)
        for image_name in os.listdir(self._save_dir):
            img = cv2.imread(os.path.join(self._save_dir, image_name))
            feat = self.reid_model(img)  # æå–ç‰¹å¾ï¼Œè¿”å›æ­£åˆ™åŒ–çš„numpyæ•°ç»„
            pytorch_output = feat.numpy()  # è½¬åŒ–æˆnumpyæ•°ç»„
            embs = np.concatenate((pytorch_output, embs), axis=0) # å’Œå·²æœ‰çš„ç‰¹å¾å‘é‡æ•°ç»„embsåœ¨ç¬¬0ç»´ä¸Šè¿›è¡Œæ‹¼æ¥ï¼Œå¾—åˆ°æ›´æ–°åçš„embsæ•°ç»„
            names.append(image_name[0:-4])  # å»é™¤.jpgä½œä¸ºé¡¾å®¢çš„åå­—
        names = names[::-1] # å€’åºç¿»è½¬ [1, 2, 3, 4, 5] -> [5, 4, 3, 2, 1]
        names.append("None")

        # ---------- ä¸éœ€è¦çš„ --------------------
        # ä»£ç è¯»å–ä¸€ä¸ª.npyæ–‡ä»¶ï¼Œè¯¥æ–‡ä»¶ä¸­åŒ…å«äº†ä¸€ä¸ªç‰¹å¾å‘é‡queryï¼Œå°†å¦å¤–ä¸€ç»„ç‰¹å¾å‘é‡embsä¸queryè®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        # path = '{}.npy'.format(str(feat_path))
        # feats = np.load(path)

        # cos_sim = cosine_similarity(embs, query)
        # max_idx = np.argmax(cos_sim, axis=1)
        # maximum = np.max(cos_sim, axis=1)
        # max_idx[maximum < 0.6] = -1
        print("Succeed extracting features for ReID.")

        # return feats, names
        return embs, names # å°±å®Œå…¨ä¸å½±å“

    def save_feats_names_to_dir(self, embs, names):
        feat_path = os.path.join(str(self._save_dir), '..', 'query_features')
        names_path = os.path.join(str(self._save_dir), '..', 'names')
        # å®é™…ä¿å­˜çš„æ˜¯embsæ•°ç»„ä¸­é™¤äº†æœ€åä¸€è¡Œä»¥å¤–çš„æ‰€æœ‰è¡Œ
        np.save(feat_path, embs[:-1, :])  # å°†numpyæ•°ç»„ embs çš„ç¬¬ä¸€ç»´åº¦çš„æ‰€æœ‰å…ƒç´ ï¼ˆé™¤äº†æœ€åä¸€ä¸ªå…ƒç´ ï¼‰ä¿å­˜ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶çš„æ“ä½œï¼Œæ–‡ä»¶åä¸º feat_path
        np.save(names_path, names)  # save query
        print("[INFO] save query_features.npy & names.npy")

    def get_customer_logs(self):
        return self.customers_log